#!/usr/bin/env python
import glob
import numpy as np
import os
import sys
import pprint

import fitsio
import h5py
from esutil.pbar import PBar

SHEARS = ["noshear", "1p", "1m", "2p", "2m"]


def get_args():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--output-file-base',
        help='the output file name',
        required=True,
    )
    parser.add_argument(
        '--input-file-dir',
        help='the input FITS file directory',
        required=True,
    )

    return parser.parse_args()


def _write_to_patch_num(d, patch_num, num_per_shear, fptrs, ofile_base_hdf5):
    if patch_num == -1:
        pmsk = d["mdet_flags"] == 0
    else:
        pmsk = d["patch_num"] == patch_num

    if patch_num not in num_per_shear:
        num_per_shear[patch_num] = {k: 0 for k in SHEARS}
        ofile_hdf5 = _get_fname(ofile_base_hdf5, patch_num)
        _make_h5_file(ofile_hdf5, d)
        fptrs[patch_num] = h5py.File(ofile_hdf5, "a")

    fp = fptrs[patch_num]

    for mdet_step in SHEARS:
        msk = (d["mdet_step"] == mdet_step) & pmsk
        d_mdet = d[msk]
        loc = num_per_shear[patch_num][mdet_step]
        _num = d_mdet.shape[0]
        if _num > 0:
            for col in d.dtype.names:
                if col == "mdet_step":
                    continue
                fp["mdet"][mdet_step][col][loc:loc + _num] = d_mdet[col].astype(fp["mdet"][mdet_step][col].dtype)

            num_per_shear[patch_num][mdet_step] += _num

    return num_per_shear, fptrs


def _process_file(*, fname, num_per_shear, fptrs, ofile_base_hdf5):
    d = fitsio.read(fname, ext=1)

    if d.shape[0] == 0:
        return num_per_shear, fptrs

    patch_nums = np.unique(d["patch_num"])
    for patch_num in patch_nums:
        num_per_shear, fptrs = _write_to_patch_num(d, patch_num, num_per_shear, fptrs, ofile_base_hdf5)

    patch_num = -1
    num_per_shear, fptrs = _write_to_patch_num(d, patch_num, num_per_shear, fptrs, ofile_base_hdf5)

    return num_per_shear, fptrs


def _get_fname(ofile_base_hdf5, patch_num):
    if patch_num == -1:
        return f"{ofile_base_hdf5}_all.h5"
    else:
        return f"{ofile_base_hdf5}_patch{patch_num:03d}.h5"


def _make_h5_file(ofile_hdf5, d):
    print(f"\ncreating output file {ofile_hdf5}...", flush=True)
    with h5py.File(ofile_hdf5, "w") as fp:
        mdet_grp = fp.create_group("mdet")
        for mdet_step in SHEARS:
            grp = mdet_grp.create_group(mdet_step)
            for col in d.dtype.names:
                if col == "mdet_step":
                    continue
                dt = d[col].dtype
                if col.endswith("_nodered"):
                    dt = np.dtype(">f4")
                elif col == "tilename":
                    dt = np.dtype("<S12")
                elif col == "mdet_step":
                    dt = np.dtype("<S7")

                grp.create_dataset(
                    col,
                    dtype=dt,
                    shape=(160_000_000,),
                    maxshape=(None,),
                    chunks=(5_000_000,),
                )
    os.system(f"chmod go-rwx {ofile_hdf5}")


def main(args):
    ofile_base_hdf5 = args.output_file_base

    cut_files = sorted(glob.glob(
        os.path.join(args.input_file_dir, "*.fits")
    ))
    print(f"found {len(cut_files)} input files...", flush=True)

    print(f"removing output file(s) {ofile_base_hdf5}_*.h5...", flush=True)
    for ofname in glob.glob(f"{ofile_base_hdf5}_patch*.h5"):
        os.system(f"rm -f {ofname}")
    os.system(f"rm -f {ofile_base_hdf5}_all.h5")

    try:
        num_per_shear = dict()
        fptrs = {}
        for i, fname in PBar(
            enumerate(cut_files),
            desc="processing FITS files",
            total=len(cut_files),
            file=sys.stdout,
        ):
            num_per_shear, fptrs = _process_file(
                fname=fname,
                num_per_shear=num_per_shear,
                fptrs=fptrs,
                ofile_base_hdf5=ofile_base_hdf5,
            )
            if i % 100 == 0:
                num = num_per_shear[-1]["noshear"]
                print(
                    f"\nexpecting ~{num/(i+1)*len(cut_files)/1e6:6.2f} "
                    f"million objects ({num/1e6:6.2f} million so far)",
                    flush=True,
                )
                for _, fp in fptrs.items():
                    fp.flush()
    finally:
        for _, fp in fptrs.items():
            fp.close()

    print("final counts:\n", pprint.pformat(num_per_shear), flush=True)

    print("resizing final datasets...", flush=True)
    for key, nums in PBar(
        num_per_shear.items(),
        desc="resizing datasets",
        total=len(num_per_shear),
        file=sys.stdout,
    ):
        ofile_hdf5 = _get_fname(ofile_base_hdf5, key)
        with h5py.File(ofile_hdf5, "a") as fp:
            for shear in SHEARS:
                sgrp = fp["mdet"][shear]
                for dset in sgrp.values():
                    dset.resize(nums[shear], axis=0)
        os.system(f"chmod u-w {ofile_hdf5}")


if __name__ == '__main__':
    args = get_args()
    main(args)
